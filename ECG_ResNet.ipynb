{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a504aa-d6a8-4ad6-ad84-cf213700ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Dataset Init...\n",
      "Scanning files in C:\\Users\\fujiw\\OneDrive\\デスクトップ\\ECG_ResNet\\stage2...\n",
      "Found 4395 files. Loading into RAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-loading: 100%|█████████████| 4395/4395 [02:15<00:00, 32.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4395 samples.\n",
      "Scanning files in C:\\Users\\fujiw\\OneDrive\\デスクトップ\\ECG_ResNet\\stage2...\n",
      "Found 490 files. Loading into RAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-loading: 100%|███████████████| 490/490 [00:19<00:00, 24.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 490 samples.\n",
      "Training Started (Large Model)...\n",
      "\n",
      "==================== Epoch 1/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 1): 100%|█| 138/138 [00:09<00:00, 15.00it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 1] Train Loss: 0.088418 | Val Loss: 0.019111 | LR: 1.0e-03\n",
      "score improved: inf --> 0.019111\n",
      "\n",
      "==================== Epoch 2/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 2): 100%|█| 138/138 [00:09<00:00, 15.28it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 2] Train Loss: 0.023115 | Val Loss: 0.017170 | LR: 1.0e-03\n",
      "score improved: 0.019111 --> 0.017170\n",
      "\n",
      "==================== Epoch 3/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 3): 100%|█| 138/138 [00:09<00:00, 15.28it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 3] Train Loss: 0.019875 | Val Loss: 0.016543 | LR: 1.0e-03\n",
      "score improved: 0.017170 --> 0.016543\n",
      "\n",
      "==================== Epoch 4/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 4): 100%|█| 138/138 [00:09<00:00, 15.32it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 4] Train Loss: 0.018292 | Val Loss: 0.015510 | LR: 1.0e-03\n",
      "score improved: 0.016543 --> 0.015510\n",
      "\n",
      "==================== Epoch 5/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 5): 100%|█| 138/138 [00:09<00:00, 15.29it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 5] Train Loss: 0.016751 | Val Loss: 0.014405 | LR: 1.0e-03\n",
      "score improved: 0.015510 --> 0.014405\n",
      "\n",
      "==================== Epoch 6/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 6): 100%|█| 138/138 [00:09<00:00, 15.29it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 6] Train Loss: 0.015989 | Val Loss: 0.014777 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 7/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 7): 100%|█| 138/138 [00:09<00:00, 15.28it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 7] Train Loss: 0.015400 | Val Loss: 0.014541 | LR: 1.0e-03\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 8/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 8): 100%|█| 138/138 [00:09<00:00, 15.29it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 8] Train Loss: 0.014024 | Val Loss: 0.012669 | LR: 1.0e-03\n",
      "score improved: 0.014405 --> 0.012669\n",
      "\n",
      "==================== Epoch 9/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 9): 100%|█| 138/138 [00:09<00:00, 15.26it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 9] Train Loss: 0.013984 | Val Loss: 0.013151 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 10/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 10): 100%|█| 138/138 [00:09<00:00, 15.16it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 10] Train Loss: 0.013680 | Val Loss: 0.012748 | LR: 1.0e-03\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 11/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 11): 100%|█| 138/138 [00:09<00:00, 15.09it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 11] Train Loss: 0.013594 | Val Loss: 0.014208 | LR: 1.0e-03\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 12/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 12): 100%|█| 138/138 [00:09<00:00, 15.21it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 12] Train Loss: 0.012815 | Val Loss: 0.012941 | LR: 1.0e-03\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 13/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 13): 100%|█| 138/138 [00:09<00:00, 15.22it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 13] Train Loss: 0.012046 | Val Loss: 0.012290 | LR: 1.0e-03\n",
      "score improved: 0.012669 --> 0.012290\n",
      "\n",
      "==================== Epoch 14/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 14): 100%|█| 138/138 [00:09<00:00, 15.24it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 14] Train Loss: 0.011440 | Val Loss: 0.013258 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 15/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 15): 100%|█| 138/138 [00:09<00:00, 15.22it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 15] Train Loss: 0.011831 | Val Loss: 0.013593 | LR: 1.0e-03\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 16/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 16): 100%|█| 138/138 [00:09<00:00, 14.99it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 16] Train Loss: 0.010953 | Val Loss: 0.012299 | LR: 1.0e-03\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 17/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 17): 100%|█| 138/138 [00:09<00:00, 14.31it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 17] Train Loss: 0.010291 | Val Loss: 0.012748 | LR: 1.0e-03\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 18/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 18): 100%|█| 138/138 [00:09<00:00, 14.40it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 18] Train Loss: 0.009730 | Val Loss: 0.013021 | LR: 1.0e-03\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 19/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 19): 100%|█| 138/138 [00:09<00:00, 14.40it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 19] Train Loss: 0.009979 | Val Loss: 0.012774 | LR: 1.0e-03\n",
      "No improvement. Patience: 6/20\n",
      "\n",
      "==================== Epoch 20/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 20): 100%|█| 138/138 [00:09<00:00, 14.22it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 20] Train Loss: 0.009429 | Val Loss: 0.011633 | LR: 1.0e-03\n",
      "score improved: 0.012290 --> 0.011633\n",
      "\n",
      "==================== Epoch 21/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 21): 100%|█| 138/138 [00:09<00:00, 14.55it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 21] Train Loss: 0.010196 | Val Loss: 0.011628 | LR: 1.0e-03\n",
      "score improved: 0.011633 --> 0.011628\n",
      "\n",
      "==================== Epoch 22/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 22): 100%|█| 138/138 [00:09<00:00, 15.23it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 22] Train Loss: 0.008880 | Val Loss: 0.013691 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 23/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 23): 100%|█| 138/138 [00:09<00:00, 15.11it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 23] Train Loss: 0.008529 | Val Loss: 0.010467 | LR: 1.0e-03\n",
      "score improved: 0.011628 --> 0.010467\n",
      "\n",
      "==================== Epoch 24/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 24): 100%|█| 138/138 [00:08<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 24] Train Loss: 0.008286 | Val Loss: 0.011090 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 25/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 25): 100%|█| 138/138 [00:09<00:00, 15.30it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 25] Train Loss: 0.007982 | Val Loss: 0.011323 | LR: 1.0e-03\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 26/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 26): 100%|█| 138/138 [00:09<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 26] Train Loss: 0.007812 | Val Loss: 0.011265 | LR: 1.0e-03\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 27/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 27): 100%|█| 138/138 [00:09<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 27] Train Loss: 0.007268 | Val Loss: 0.010970 | LR: 1.0e-03\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 28/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 28): 100%|█| 138/138 [00:09<00:00, 15.25it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 28] Train Loss: 0.007476 | Val Loss: 0.010990 | LR: 1.0e-03\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 29/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 29): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 29] Train Loss: 0.007340 | Val Loss: 0.010788 | LR: 1.0e-03\n",
      "No improvement. Patience: 6/20\n",
      "\n",
      "==================== Epoch 30/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 30): 100%|█| 138/138 [00:09<00:00, 15.24it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 30] Train Loss: 0.007087 | Val Loss: 0.011619 | LR: 1.0e-03\n",
      "No improvement. Patience: 7/20\n",
      "\n",
      "==================== Epoch 31/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 31): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 31] Train Loss: 0.007368 | Val Loss: 0.010375 | LR: 1.0e-03\n",
      "score improved: 0.010467 --> 0.010375\n",
      "\n",
      "==================== Epoch 32/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 32): 100%|█| 138/138 [00:09<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 32] Train Loss: 0.006813 | Val Loss: 0.010614 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 33/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 33): 100%|█| 138/138 [00:08<00:00, 15.35it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 33] Train Loss: 0.006900 | Val Loss: 0.012030 | LR: 1.0e-03\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 34/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 34): 100%|█| 138/138 [00:09<00:00, 15.16it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 34] Train Loss: 0.006950 | Val Loss: 0.011591 | LR: 1.0e-03\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 35/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 35): 100%|█| 138/138 [00:09<00:00, 15.25it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 35] Train Loss: 0.006599 | Val Loss: 0.011492 | LR: 1.0e-03\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 36/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 36): 100%|█| 138/138 [00:09<00:00, 15.16it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 36] Train Loss: 0.006807 | Val Loss: 0.010497 | LR: 1.0e-03\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 37/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 37): 100%|█| 138/138 [00:09<00:00, 15.30it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 37] Train Loss: 0.005777 | Val Loss: 0.010351 | LR: 1.0e-03\n",
      "score improved: 0.010375 --> 0.010351\n",
      "\n",
      "==================== Epoch 38/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 38): 100%|█| 138/138 [00:09<00:00, 15.31it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 38] Train Loss: 0.006299 | Val Loss: 0.012236 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 39/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 39): 100%|█| 138/138 [00:09<00:00, 15.28it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 39] Train Loss: 0.007510 | Val Loss: 0.010632 | LR: 1.0e-03\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 40/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 40): 100%|█| 138/138 [00:09<00:00, 15.27it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 40] Train Loss: 0.005973 | Val Loss: 0.011221 | LR: 1.0e-03\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 41/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 41): 100%|█| 138/138 [00:09<00:00, 15.25it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 41] Train Loss: 0.005548 | Val Loss: 0.012178 | LR: 1.0e-03\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 42/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 42): 100%|█| 138/138 [00:08<00:00, 15.35it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 42] Train Loss: 0.005382 | Val Loss: 0.011353 | LR: 1.0e-03\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 43/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 43): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 43] Train Loss: 0.005159 | Val Loss: 0.010706 | LR: 1.0e-03\n",
      "No improvement. Patience: 6/20\n",
      "\n",
      "==================== Epoch 44/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 44): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 44] Train Loss: 0.004993 | Val Loss: 0.010650 | LR: 1.0e-03\n",
      "No improvement. Patience: 7/20\n",
      "\n",
      "==================== Epoch 45/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 45): 100%|█| 138/138 [00:08<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 45] Train Loss: 0.005534 | Val Loss: 0.011516 | LR: 1.0e-03\n",
      "No improvement. Patience: 8/20\n",
      "\n",
      "==================== Epoch 46/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 46): 100%|█| 138/138 [00:08<00:00, 15.38it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 46] Train Loss: 0.004478 | Val Loss: 0.009282 | LR: 1.0e-04\n",
      "score improved: 0.010351 --> 0.009282\n",
      "\n",
      "==================== Epoch 47/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 47): 100%|█| 138/138 [00:09<00:00, 15.27it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 47] Train Loss: 0.003920 | Val Loss: 0.009287 | LR: 1.0e-04\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 48/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 48): 100%|█| 138/138 [00:09<00:00, 15.30it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 48] Train Loss: 0.003438 | Val Loss: 0.009336 | LR: 1.0e-04\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 49/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 49): 100%|█| 138/138 [00:09<00:00, 15.22it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 49] Train Loss: 0.003227 | Val Loss: 0.009410 | LR: 1.0e-04\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 50/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 50): 100%|█| 138/138 [00:09<00:00, 15.23it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 50] Train Loss: 0.003199 | Val Loss: 0.009356 | LR: 1.0e-04\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 51/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 51): 100%|█| 138/138 [00:09<00:00, 15.31it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 51] Train Loss: 0.003124 | Val Loss: 0.009268 | LR: 1.0e-04\n",
      "score improved: 0.009282 --> 0.009268\n",
      "\n",
      "==================== Epoch 52/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 52): 100%|█| 138/138 [00:09<00:00, 15.17it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 52] Train Loss: 0.003002 | Val Loss: 0.009301 | LR: 1.0e-04\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 53/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 53): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 53] Train Loss: 0.002998 | Val Loss: 0.009292 | LR: 1.0e-04\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 54/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 54): 100%|█| 138/138 [00:08<00:00, 15.38it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 54] Train Loss: 0.002931 | Val Loss: 0.009288 | LR: 1.0e-04\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 55/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 55): 100%|█| 138/138 [00:08<00:00, 15.37it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 55] Train Loss: 0.002872 | Val Loss: 0.009382 | LR: 1.0e-04\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 56/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 56): 100%|█| 138/138 [00:08<00:00, 15.36it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 56] Train Loss: 0.002879 | Val Loss: 0.009197 | LR: 1.0e-04\n",
      "score improved: 0.009268 --> 0.009197\n",
      "\n",
      "==================== Epoch 57/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 57): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 57] Train Loss: 0.002888 | Val Loss: 0.009421 | LR: 1.0e-04\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 58/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 58): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 58] Train Loss: 0.002840 | Val Loss: 0.009316 | LR: 1.0e-04\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 59/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 59): 100%|█| 138/138 [00:09<00:00, 15.28it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 59] Train Loss: 0.002783 | Val Loss: 0.009300 | LR: 1.0e-04\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 60/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 60): 100%|█| 138/138 [00:08<00:00, 15.38it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 60] Train Loss: 0.002807 | Val Loss: 0.009257 | LR: 1.0e-04\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 61/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 61): 100%|█| 138/138 [00:09<00:00, 15.18it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 61] Train Loss: 0.002758 | Val Loss: 0.009224 | LR: 1.0e-04\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 62/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 62): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 62] Train Loss: 0.002673 | Val Loss: 0.009200 | LR: 1.0e-04\n",
      "No improvement. Patience: 6/20\n",
      "\n",
      "==================== Epoch 63/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 63): 100%|█| 138/138 [00:09<00:00, 15.28it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 63] Train Loss: 0.002629 | Val Loss: 0.009275 | LR: 1.0e-04\n",
      "No improvement. Patience: 7/20\n",
      "\n",
      "==================== Epoch 64/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 64): 100%|█| 138/138 [00:09<00:00, 15.30it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 64] Train Loss: 0.002642 | Val Loss: 0.009242 | LR: 1.0e-04\n",
      "No improvement. Patience: 8/20\n",
      "\n",
      "==================== Epoch 65/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 65): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 65] Train Loss: 0.002541 | Val Loss: 0.009176 | LR: 1.0e-05\n",
      "score improved: 0.009197 --> 0.009176\n",
      "\n",
      "==================== Epoch 66/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 66): 100%|█| 138/138 [00:09<00:00, 15.25it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 66] Train Loss: 0.002478 | Val Loss: 0.009192 | LR: 1.0e-05\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 67/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 67): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 67] Train Loss: 0.002479 | Val Loss: 0.009228 | LR: 1.0e-05\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 68/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 68): 100%|█| 138/138 [00:09<00:00, 15.27it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 68] Train Loss: 0.002504 | Val Loss: 0.009195 | LR: 1.0e-05\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 69/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 69): 100%|█| 138/138 [00:09<00:00, 15.26it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 69] Train Loss: 0.002475 | Val Loss: 0.009188 | LR: 1.0e-05\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 70/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 70): 100%|█| 138/138 [00:09<00:00, 15.29it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 70] Train Loss: 0.002474 | Val Loss: 0.009152 | LR: 1.0e-05\n",
      "score improved: 0.009176 --> 0.009152\n",
      "\n",
      "==================== Epoch 71/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 71): 100%|█| 138/138 [00:08<00:00, 15.35it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 71] Train Loss: 0.002490 | Val Loss: 0.009147 | LR: 1.0e-05\n",
      "score improved: 0.009152 --> 0.009147\n",
      "\n",
      "==================== Epoch 72/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 72): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 72] Train Loss: 0.002465 | Val Loss: 0.009190 | LR: 1.0e-05\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 73/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 73): 100%|█| 138/138 [00:08<00:00, 15.38it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 73] Train Loss: 0.002469 | Val Loss: 0.009201 | LR: 1.0e-05\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 74/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 74): 100%|█| 138/138 [00:09<00:00, 15.17it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 74] Train Loss: 0.002463 | Val Loss: 0.009222 | LR: 1.0e-05\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 75/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 75): 100%|█| 138/138 [00:08<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 75] Train Loss: 0.002460 | Val Loss: 0.009207 | LR: 1.0e-05\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 76/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 76): 100%|█| 138/138 [00:09<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 76] Train Loss: 0.002452 | Val Loss: 0.009224 | LR: 1.0e-05\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 77/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 77): 100%|█| 138/138 [00:08<00:00, 15.37it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 77] Train Loss: 0.002462 | Val Loss: 0.009165 | LR: 1.0e-05\n",
      "No improvement. Patience: 6/20\n",
      "\n",
      "==================== Epoch 78/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 78): 100%|█| 138/138 [00:08<00:00, 15.36it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 78] Train Loss: 0.002441 | Val Loss: 0.009194 | LR: 1.0e-05\n",
      "No improvement. Patience: 7/20\n",
      "\n",
      "==================== Epoch 79/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 79): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 79] Train Loss: 0.002501 | Val Loss: 0.009206 | LR: 1.0e-05\n",
      "No improvement. Patience: 8/20\n",
      "\n",
      "==================== Epoch 80/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 80): 100%|█| 138/138 [00:08<00:00, 15.38it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 80] Train Loss: 0.002413 | Val Loss: 0.009150 | LR: 1.0e-06\n",
      "No improvement. Patience: 9/20\n",
      "\n",
      "==================== Epoch 81/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 81): 100%|█| 138/138 [00:08<00:00, 15.36it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 81] Train Loss: 0.002416 | Val Loss: 0.009191 | LR: 1.0e-06\n",
      "No improvement. Patience: 10/20\n",
      "\n",
      "==================== Epoch 82/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 82): 100%|█| 138/138 [00:09<00:00, 15.29it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 82] Train Loss: 0.002408 | Val Loss: 0.009195 | LR: 1.0e-06\n",
      "No improvement. Patience: 11/20\n",
      "\n",
      "==================== Epoch 83/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 83): 100%|█| 138/138 [00:08<00:00, 15.35it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 83] Train Loss: 0.002435 | Val Loss: 0.009240 | LR: 1.0e-06\n",
      "No improvement. Patience: 12/20\n",
      "\n",
      "==================== Epoch 84/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 84): 100%|█| 138/138 [00:09<00:00, 15.28it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 84] Train Loss: 0.002410 | Val Loss: 0.009211 | LR: 1.0e-06\n",
      "No improvement. Patience: 13/20\n",
      "\n",
      "==================== Epoch 85/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 85): 100%|█| 138/138 [00:09<00:00, 15.33it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 85] Train Loss: 0.002403 | Val Loss: 0.009188 | LR: 1.0e-06\n",
      "No improvement. Patience: 14/20\n",
      "\n",
      "==================== Epoch 86/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 86): 100%|█| 138/138 [00:09<00:00, 15.30it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 86] Train Loss: 0.002414 | Val Loss: 0.009212 | LR: 1.0e-06\n",
      "No improvement. Patience: 15/20\n",
      "\n",
      "==================== Epoch 87/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 87): 100%|█| 138/138 [00:09<00:00, 15.21it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 87] Train Loss: 0.002413 | Val Loss: 0.009210 | LR: 1.0e-06\n",
      "No improvement. Patience: 16/20\n",
      "\n",
      "==================== Epoch 88/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 88): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 88] Train Loss: 0.002405 | Val Loss: 0.009173 | LR: 1.0e-07\n",
      "No improvement. Patience: 17/20\n",
      "\n",
      "==================== Epoch 89/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 89): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 89] Train Loss: 0.002412 | Val Loss: 0.009178 | LR: 1.0e-07\n",
      "No improvement. Patience: 18/20\n",
      "\n",
      "==================== Epoch 90/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 90): 100%|█| 138/138 [00:09<00:00, 15.31it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 90] Train Loss: 0.002474 | Val Loss: 0.009144 | LR: 1.0e-07\n",
      "score improved: 0.009147 --> 0.009144\n",
      "\n",
      "==================== Epoch 91/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 91): 100%|█| 138/138 [00:09<00:00, 15.27it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 91] Train Loss: 0.002407 | Val Loss: 0.009195 | LR: 1.0e-07\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 92/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 92): 100%|█| 138/138 [00:09<00:00, 15.30it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 92] Train Loss: 0.002425 | Val Loss: 0.009173 | LR: 1.0e-07\n",
      "No improvement. Patience: 2/20\n",
      "\n",
      "==================== Epoch 93/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 93): 100%|█| 138/138 [00:09<00:00, 15.28it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 93] Train Loss: 0.002450 | Val Loss: 0.009146 | LR: 1.0e-07\n",
      "No improvement. Patience: 3/20\n",
      "\n",
      "==================== Epoch 94/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 94): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 94] Train Loss: 0.002418 | Val Loss: 0.009168 | LR: 1.0e-07\n",
      "No improvement. Patience: 4/20\n",
      "\n",
      "==================== Epoch 95/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 95): 100%|█| 138/138 [00:09<00:00, 15.28it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 95] Train Loss: 0.002422 | Val Loss: 0.009153 | LR: 1.0e-07\n",
      "No improvement. Patience: 5/20\n",
      "\n",
      "==================== Epoch 96/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 96): 100%|█| 138/138 [00:08<00:00, 15.34it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 96] Train Loss: 0.002425 | Val Loss: 0.009153 | LR: 1.0e-07\n",
      "No improvement. Patience: 6/20\n",
      "\n",
      "==================== Epoch 97/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 97): 100%|█| 138/138 [00:08<00:00, 15.37it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 97] Train Loss: 0.002444 | Val Loss: 0.009194 | LR: 1.0e-07\n",
      "No improvement. Patience: 7/20\n",
      "\n",
      "==================== Epoch 98/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 98): 100%|█| 138/138 [00:09<00:00, 15.32it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 98] Train Loss: 0.002422 | Val Loss: 0.009176 | LR: 1.0e-07\n",
      "No improvement. Patience: 8/20\n",
      "\n",
      "==================== Epoch 99/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 99): 100%|█| 138/138 [00:09<00:00, 15.21it/s, los\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 99] Train Loss: 0.002416 | Val Loss: 0.009184 | LR: 1.0e-08\n",
      "No improvement. Patience: 9/20\n",
      "\n",
      "==================== Epoch 100/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 100): 100%|█| 138/138 [00:08<00:00, 15.34it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 100] Train Loss: 0.002417 | Val Loss: 0.009155 | LR: 1.0e-08\n",
      "No improvement. Patience: 10/20\n",
      "\n",
      "==================== Epoch 101/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 101): 100%|█| 138/138 [00:08<00:00, 15.34it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 101] Train Loss: 0.002397 | Val Loss: 0.009207 | LR: 1.0e-08\n",
      "No improvement. Patience: 11/20\n",
      "\n",
      "==================== Epoch 102/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 102): 100%|█| 138/138 [00:08<00:00, 15.35it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 102] Train Loss: 0.002418 | Val Loss: 0.009211 | LR: 1.0e-08\n",
      "No improvement. Patience: 12/20\n",
      "\n",
      "==================== Epoch 103/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 103): 100%|█| 138/138 [00:09<00:00, 15.33it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 103] Train Loss: 0.002431 | Val Loss: 0.009173 | LR: 1.0e-08\n",
      "No improvement. Patience: 13/20\n",
      "\n",
      "==================== Epoch 104/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 104): 100%|█| 138/138 [00:09<00:00, 15.26it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 104] Train Loss: 0.002433 | Val Loss: 0.009196 | LR: 1.0e-08\n",
      "No improvement. Patience: 14/20\n",
      "\n",
      "==================== Epoch 105/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 105): 100%|█| 138/138 [00:08<00:00, 15.34it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 105] Train Loss: 0.002419 | Val Loss: 0.009156 | LR: 1.0e-08\n",
      "No improvement. Patience: 15/20\n",
      "\n",
      "==================== Epoch 106/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 106): 100%|█| 138/138 [00:09<00:00, 15.32it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 106] Train Loss: 0.002423 | Val Loss: 0.009191 | LR: 1.0e-08\n",
      "No improvement. Patience: 16/20\n",
      "\n",
      "==================== Epoch 107/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 107): 100%|█| 138/138 [00:08<00:00, 15.36it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 107] Train Loss: 0.002423 | Val Loss: 0.009158 | LR: 1.0e-08\n",
      "No improvement. Patience: 17/20\n",
      "\n",
      "==================== Epoch 108/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 108): 100%|█| 138/138 [00:09<00:00, 15.33it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 108] Train Loss: 0.002415 | Val Loss: 0.009186 | LR: 1.0e-08\n",
      "No improvement. Patience: 18/20\n",
      "\n",
      "==================== Epoch 109/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 109): 100%|█| 138/138 [00:09<00:00, 15.33it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 109] Train Loss: 0.002427 | Val Loss: 0.009204 | LR: 1.0e-08\n",
      "No improvement. Patience: 19/20\n",
      "\n",
      "==================== Epoch 110/200 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 110): 100%|█| 138/138 [00:09<00:00, 15.29it/s, lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 110] Train Loss: 0.002401 | Val Loss: 0.009215 | LR: 1.0e-08\n",
      "No improvement. Patience: 20/20\n",
      "Early Stopping!\n",
      "All Finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.signal import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 0. 設定エリア\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\Users\\fujiw\\OneDrive\\デスクトップ\\ECG_ResNet\"\n",
    "\n",
    "STAGE2_DIR = os.path.join(BASE_DIR, \"stage2\")       # NPYフォルダ\n",
    "CSV_DIR    = os.path.join(BASE_DIR, \"train_csvs\")   # CSVフォルダ\n",
    "TRAIN_META = os.path.join(BASE_DIR, \"train.csv\")    # train.csv\n",
    "SAVE_DIR   = os.path.join(BASE_DIR, \"models\")       # 保存先\n",
    "\n",
    "# ★モデルを大きくしたので、VRAM不足を防ぐためにバッチサイズを少し下げます\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "LR = 1e-3\n",
    "\n",
    "# =========================================================\n",
    "# 1. Dataset Class (正規化を追加)\n",
    "# =========================================================\n",
    "class ECGDatasetRam(Dataset):\n",
    "    def __init__(self, df, npy_dir, csv_dir, target_len=5000):\n",
    "        self.target_len = target_len\n",
    "        self.samples = [] \n",
    "        \n",
    "        if not os.path.exists(npy_dir):\n",
    "            raise FileNotFoundError(f\"Directory not found: {npy_dir}\")\n",
    "            \n",
    "        target_ids = set(df['id'].astype(str).tolist())\n",
    "        file_list = []\n",
    "        all_files = glob.glob(os.path.join(npy_dir, \"*.npy\"))\n",
    "        \n",
    "        print(f\"Scanning files in {npy_dir}...\")\n",
    "        for fpath in all_files:\n",
    "            fname = os.path.basename(fpath)\n",
    "            file_id = fname.split('-')[0]\n",
    "            if file_id in target_ids:\n",
    "                file_list.append((fpath, file_id))\n",
    "        \n",
    "        print(f\"Found {len(file_list)} files. Loading into RAM...\")\n",
    "\n",
    "        for fpath, sample_id in tqdm(file_list, desc=\"Pre-loading\"):\n",
    "            processed = self.process_one_file(fpath, sample_id, csv_dir)\n",
    "            if processed is not None:\n",
    "                self.samples.append(processed)\n",
    "                \n",
    "        print(f\"Loaded {len(self.samples)} samples.\")\n",
    "\n",
    "    def process_one_file(self, npy_path, sample_id, csv_dir):\n",
    "        try:\n",
    "            # Input\n",
    "            data = np.load(npy_path)\n",
    "            data = np.nan_to_num(data, nan=0.0)\n",
    "            original_len = data.shape[1]\n",
    "            if data.shape[0] != 13: return None\n",
    "\n",
    "            reconstructed = np.zeros((12, original_len), dtype=np.float32)\n",
    "            for i in range(4):\n",
    "                sig_row = data[i]\n",
    "                id_row = data[9+i]\n",
    "                unique_ids = np.unique(id_row)\n",
    "                for uid in unique_ids:\n",
    "                    if 0 <= uid <= 11:\n",
    "                        mask_ch = (id_row == uid)\n",
    "                        reconstructed[int(uid), mask_ch] = sig_row[mask_ch]\n",
    "            \n",
    "            # Target\n",
    "            csv_path = os.path.join(csv_dir, f\"{sample_id}.csv\")\n",
    "            if not os.path.exists(csv_path): return None\n",
    "\n",
    "            target_df = pd.read_csv(csv_path)\n",
    "            target_vals = target_df.values.T \n",
    "            mask_data = (~np.isnan(target_vals)).astype(np.float32)\n",
    "            target_data = np.nan_to_num(target_vals, nan=0.0)\n",
    "            \n",
    "            # Resample\n",
    "            if reconstructed.shape[1] != self.target_len:\n",
    "                input_final = resample(reconstructed, self.target_len, axis=1)\n",
    "            else:\n",
    "                input_final = reconstructed\n",
    "                \n",
    "            if target_data.shape[1] != self.target_len:\n",
    "                target_final = resample(target_data, self.target_len, axis=1)\n",
    "                mask_final = resample(mask_data, self.target_len, axis=1)\n",
    "            else:\n",
    "                target_final = target_data\n",
    "                mask_final = mask_data\n",
    "\n",
    "            # ★【重要】正規化 (Standardization)\n",
    "            # モデルを巨大化する場合、入力値のスケールが揃っていないと学習が発散します。\n",
    "            # データそのものは変えませんが、平均0・分散1に揃えます。\n",
    "            mean = np.mean(input_final, axis=1, keepdims=True)\n",
    "            std = np.std(input_final, axis=1, keepdims=True) + 1e-6\n",
    "            input_final = (input_final - mean) / std\n",
    "            \n",
    "            return (np.nan_to_num(input_final).astype(np.float32), \n",
    "                    np.nan_to_num(target_final).astype(np.float32), \n",
    "                    (mask_final > 0.5).astype(np.float32), \n",
    "                    original_len)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        in_arr, tgt_arr, msk_arr, length = self.samples[idx]\n",
    "        return (torch.from_numpy(in_arr), torch.from_numpy(tgt_arr), \n",
    "                torch.from_numpy(msk_arr), torch.tensor(length, dtype=torch.long))\n",
    "\n",
    "# =========================================================\n",
    "# 2. Model (Large Version: チャネル数倍増・Dropout追加)\n",
    "# =========================================================\n",
    "class ResNet1d_UNet_Large(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ★チャネル数を大幅に増加 (12 -> 128 スタート)\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(nn.Conv1d(12, 128, 7, 2, 3), nn.BatchNorm1d(128), nn.ReLU())\n",
    "        self.enc2 = nn.Sequential(nn.Conv1d(128, 256, 3, 2, 1), nn.BatchNorm1d(256), nn.ReLU())\n",
    "        self.enc3 = nn.Sequential(nn.Conv1d(256, 512, 3, 2, 1), nn.BatchNorm1d(512), nn.ReLU())\n",
    "        self.enc4 = nn.Sequential(nn.Conv1d(512, 1024, 3, 2, 1), nn.BatchNorm1d(1024), nn.ReLU())\n",
    "        \n",
    "        # ★Dropout (過学習防止)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Decoder\n",
    "        # skip接続があるため入力チャネル数は (下層の出力 + Encoderの出力)\n",
    "        self.dec4 = nn.Sequential(nn.Conv1d(1024 + 512, 512, 3, 1, 1), nn.BatchNorm1d(512), nn.ReLU())\n",
    "        self.dec3 = nn.Sequential(nn.Conv1d(512 + 256, 256, 3, 1, 1), nn.BatchNorm1d(256), nn.ReLU())\n",
    "        self.dec2 = nn.Sequential(nn.Conv1d(256 + 128, 128, 3, 1, 1), nn.BatchNorm1d(128), nn.ReLU())\n",
    "        \n",
    "        # 最後のアップサンプル層\n",
    "        self.dec1 = nn.Sequential(nn.Conv1d(128, 64, 3, 1, 1), nn.BatchNorm1d(64), nn.ReLU())\n",
    "        \n",
    "        # 出力層 (64 -> 12)\n",
    "        self.final = nn.Conv1d(64, 12, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        \n",
    "        # Bottleneck Dropout\n",
    "        e4 = self.dropout(e4)\n",
    "        \n",
    "        # Decoder\n",
    "        d4 = torch.cat([torch.nn.functional.interpolate(e4, size=e3.shape[2]), e3], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = torch.cat([torch.nn.functional.interpolate(d4, size=e2.shape[2]), e2], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = torch.cat([torch.nn.functional.interpolate(d3, size=e1.shape[2]), e1], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        # Final Upsample (No Skip Connection here to match dimensionality)\n",
    "        d1 = torch.nn.functional.interpolate(d2, size=x.shape[2])\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        out = self.final(d1)\n",
    "        \n",
    "        return x + out\n",
    "\n",
    "# =========================================================\n",
    "# 3. Training Loop (勾配クリッピング追加)\n",
    "# =========================================================\n",
    "def run_training():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using Device: {device}\")\n",
    "    \n",
    "    if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)\n",
    "    if not os.path.exists(TRAIN_META): return\n",
    "\n",
    "    df = pd.read_csv(TRAIN_META)\n",
    "    unique_ids = df['id'].unique()\n",
    "    train_ids, val_ids = train_test_split(unique_ids, test_size=0.1, random_state=42)\n",
    "    \n",
    "    print(\"Dataset Init...\")\n",
    "    train_ds = ECGDatasetRam(df[df['id'].isin(train_ids)], STAGE2_DIR, CSV_DIR)\n",
    "    val_ds = ECGDatasetRam(df[df['id'].isin(val_ids)], STAGE2_DIR, CSV_DIR)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # ★巨大モデルを使用\n",
    "    model = ResNet1d_UNet_Large().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7)\n",
    "    \n",
    "    use_amp = torch.cuda.is_available()\n",
    "    scaler = torch.amp.GradScaler('cuda') if use_amp else None\n",
    "    criterion_raw = nn.MSELoss(reduction='none')\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"Training Started (Large Model)...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        current_epoch = epoch + 1\n",
    "        print(f\"\\n{'='*20} Epoch {current_epoch}/{EPOCHS} {'='*20}\")\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Training   (Epoch {current_epoch})\")\n",
    "        \n",
    "        for inputs, targets, masks, _ in pbar:\n",
    "            inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if use_amp:\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = (criterion_raw(outputs, targets) * masks).sum() / (masks.sum() + 1e-8)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # ★勾配クリッピング (Gradient Clipping)\n",
    "                # モデルが大きい時のエラー防止策。勾配が爆発するのを防ぎます。\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = (criterion_raw(outputs, targets) * masks).sum() / (masks.sum() + 1e-8)\n",
    "                loss.backward()\n",
    "                \n",
    "                # ★勾配クリッピング (通常版)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.6f}\"})\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Valid\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets, masks, _ in val_loader:\n",
    "                inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n",
    "                if use_amp:\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = (criterion_raw(outputs, targets) * masks).sum() / (masks.sum() + 1e-8)\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = (criterion_raw(outputs, targets) * masks).sum() / (masks.sum() + 1e-8)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Result: [Epoch {current_epoch}] Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f} | LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            print(f\"score improved: {best_loss:.6f} --> {avg_val_loss:.6f}\")\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"best_resnet1d_unet.pth\"))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "                \n",
    "    print(\"All Finished!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44922cb0-dd93-437b-b039-166b0dbd7e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Dataset Init...\n",
      "Scanning files in C:\\Users\\fujiw\\OneDrive\\デスクトップ\\ECG_ResNet\\stage2...\n",
      "Found 3516 files. Loading into RAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-loading: 100%|█████████████| 3516/3516 [00:56<00:00, 62.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3516 samples. (Augmentation: True)\n",
      "Scanning files in C:\\Users\\fujiw\\OneDrive\\デスクトップ\\ECG_ResNet\\stage2...\n",
      "Found 392 files. Loading into RAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-loading: 100%|███████████████| 392/392 [00:08<00:00, 47.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 392 samples. (Augmentation: False)\n",
      "Training Started (Large Model + Augmentation)...\n",
      "\n",
      "==================== Epoch 1/300 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 1): 100%|█| 110/110 [00:14<00:00,  7.63it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 1] Train Loss: 0.011468 | Val Loss: 0.001994 | LR: 1.0e-03\n",
      "score improved: inf --> 0.001994\n",
      "\n",
      "==================== Epoch 2/300 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 2): 100%|█| 110/110 [00:14<00:00,  7.70it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 2] Train Loss: 0.006304 | Val Loss: 0.002026 | LR: 1.0e-03\n",
      "No improvement. Patience: 1/20\n",
      "\n",
      "==================== Epoch 3/300 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 3): 100%|█| 110/110 [00:14<00:00,  7.81it/s, loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Epoch 3] Train Loss: 0.006376 | Val Loss: 0.001781 | LR: 1.0e-03\n",
      "score improved: 0.001994 --> 0.001781\n",
      "\n",
      "==================== Epoch 4/300 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   (Epoch 4):  18%|▏| 20/110 [00:02<00:11,  7.61it/s, loss=\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m--------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 428\u001b[39m\n\u001b[32m    425\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll Finished!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 370\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    367\u001b[39m train_loss = \u001b[32m0\u001b[39m\n\u001b[32m    368\u001b[39m pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining   (Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:729\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[32m    732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\profiler.py:776\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.record = torch.ops.profiler._record_function_enter_new(\n\u001b[32m    772\u001b[39m         \u001b[38;5;28mself\u001b[39m.name, \u001b[38;5;28mself\u001b[39m.args\n\u001b[32m    773\u001b[39m     )\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[32m    777\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_callbacks_on_exit:\n\u001b[32m    778\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44b216-db4d-4781-8f54-b6c3bd56eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
